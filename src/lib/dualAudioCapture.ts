/**
 * üè• DUAL AUDIO CAPTURE: The Surgery
 * 
 * Physics-based speaker identification:
 * - Microphone audio = Host speaking  
 * - System audio = Guest speaking
 * 
 * No AI. No voice recognition. Just audio routing truth.
 */

import { surgicalFlags } from './config';
import { SourceComparison, PendingTranscript } from './sourceComparison';

export interface DualAudioConfig {
  chunkDuration: number;
  minInterval: number; 
  transcriptionApiUrl: string;
  transcriptionModel: string;
}

export interface TranscriptMessage {
  id: string;
  timestamp: Date;
  speaker: 'Host' | 'Guest'; // üéØ NO MORE Speaker_0 BULLSHIT
  text: string;
  audioSource: 'microphone' | 'system'; // Track the physics
}

export class DualAudioCapture {
  // Separate streams for physics-based detection
  private micRecorder: MediaRecorder | null = null;
  private systemRecorder: MediaRecorder | null = null;
  private micStream: MediaStream | null = null;
  private systemStream: MediaStream | null = null;
  
  // Recording state
  private isRecording = false;
  private isMuted = false;
  private micChunks: Blob[] = [];
  private systemChunks: Blob[] = [];
  private lastTranscriptionTime = 0;
  
  // Callbacks
  private onTranscriptCallback?: (message: TranscriptMessage) => void;
  private onErrorCallback?: (error: string) => void;
  private config: DualAudioConfig;
  
  // üéØ SOURCE COMPARISON: The physics solution
  private sourceComparison = new SourceComparison();

  constructor(config: DualAudioConfig) {
    this.config = config;
  }

  /**
   * üé§ Phase 1: Initialize microphone capture (Host audio)
   */
  private async initializeMicrophone(): Promise<boolean> {
    try {
      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.log('üé§ Initializing microphone for Host audio...');
      }

      // Request microphone through Electron if available
      if (window.electronAPI?.requestMediaAccess) {
        const granted = await window.electronAPI.requestMediaAccess();
        if (!granted) {
          throw new Error('Microphone access denied');
        }
      }

      // Get microphone stream
      this.micStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000,
        },
        video: false
      });

      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.log('‚úÖ Microphone initialized - Host audio ready');
      }
      
      return true;
    } catch (error) {
      console.error('‚ùå Failed to initialize microphone:', error);
      this.handleError(`Microphone initialization failed: ${error instanceof Error ? error.message : String(error)}`);
      return false;
    }
  }

  /**
   * üîä Phase 2: Initialize system audio capture (Guest audio)
   */
  private async initializeSystemAudio(): Promise<boolean> {
    try {
      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.log('üîä Initializing system audio for Guest audio...');
      }

      // Request system audio permission through Electron if available
      if (window.electronAPI?.requestSystemAudioPermission) {
        const permissionStatus = await window.electronAPI.requestSystemAudioPermission();
        
        if (permissionStatus === 'denied') {
          throw new Error('System audio permission denied. Please enable Screen Recording in System Settings > Privacy & Security.');
        }
        
        if (permissionStatus === 'prompt-required') {
          console.log('üìã System audio permission will be requested...');
        }
      }

      // Request system audio via screen share (audio only)
      this.systemStream = await navigator.mediaDevices.getDisplayMedia({
        video: false,
        audio: true
      });

      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.log('‚úÖ System audio initialized - Guest audio ready');
      }

      return true;
    } catch (error) {
      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.warn('‚ö†Ô∏è System audio initialization failed:', error);
      }
      
      // Provide better error messages
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (errorMessage.includes('Permission denied') || errorMessage.includes('denied')) {
        this.handleError('System audio permission denied. Please enable Screen Recording for this app in System Settings > Privacy & Security > Screen Recording.');
      }
      
      // This is expected in many scenarios (phone calls, etc.)
      // Not a fatal error if we allow fallback
      if (surgicalFlags.ALLOW_FALLBACK_TO_SINGLE_STREAM) {
        console.log('üîÑ Falling back to microphone-only mode');
        return false; // Not fatal
      } else {
        this.handleError(`System audio required but failed: ${errorMessage}`);
        return false;
      }
    }
  }

  /**
   * üöÄ Initialize both audio streams
   */
  async initialize(): Promise<boolean> {
    try {
      // Microphone is required
      const micSuccess = await this.initializeMicrophone();
      if (!micSuccess) {
        return false;
      }

      // System audio is optional (for now)
      const systemSuccess = await this.initializeSystemAudio();
      
      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.log(`üéµ Audio initialization complete:`, {
          microphone: micSuccess,
          systemAudio: systemSuccess,
          mode: systemSuccess ? 'DUAL_STREAM' : 'SINGLE_STREAM_FALLBACK'
        });
      }

      return true; // Success if at least microphone works
    } catch (error) {
      console.error('‚ùå Failed to initialize dual audio capture:', error);
      this.handleError(`Audio initialization failed: ${error instanceof Error ? error.message : String(error)}`);
      return false;
    }
  }

  /**
   * üé¨ Start recording both streams
   */
  async startRecording(): Promise<boolean> {
    if (this.isRecording) {
      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.log('üé§ Already recording both streams');
      }
      return true;
    }

    if (!this.micStream) {
      this.handleError('Audio not initialized. Call initialize() first.');
      return false;
    }

    try {
      // Start microphone recording (Host)
      if (this.micStream) {
        this.micRecorder = new MediaRecorder(this.micStream, {
          mimeType: 'audio/webm;codecs=opus'
        });

        this.micRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            this.micChunks.push(event.data);
            console.log(`üé§ Mic chunk received: ${event.data.size} bytes`);
          } else {
            console.log('‚ö†Ô∏è Empty mic chunk received');
          }
        };

        this.micRecorder.onstop = () => {
          this.processMicrophoneAudio();
        };

        this.micRecorder.start();
      }

      // Start system audio recording (Guest) if available
      if (this.systemStream) {
        this.systemRecorder = new MediaRecorder(this.systemStream, {
          mimeType: 'audio/webm;codecs=opus'
        });

        this.systemRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            this.systemChunks.push(event.data);
          }
        };

        this.systemRecorder.onstop = () => {
          this.processSystemAudio();
        };

        this.systemRecorder.start();
      }

      this.isRecording = true;

      // Schedule regular chunk processing
      this.scheduleChunkProcessing();

      if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
        console.log('üé¨ Recording started:', {
          microphone: !!this.micRecorder,
          systemAudio: !!this.systemRecorder
        });
      }

      return true;
    } catch (error) {
      console.error('‚ùå Failed to start recording:', error);
      this.handleError(`Recording failed to start: ${error instanceof Error ? error.message : String(error)}`);
      return false;
    }
  }

  /**
   * ‚è∞ Schedule regular audio chunk processing
   */
  private scheduleChunkProcessing(): void {
    const processChunks = () => {
      console.log(`‚è∞ Processing chunks after ${this.config.chunkDuration}ms`);
      if (this.isRecording) {
        // Stop and restart recorders to get chunks
        if (this.micRecorder && this.micRecorder.state === 'recording') {
          console.log('üõë Stopping mic recorder to process chunks');
          this.micRecorder.stop();
        }
        if (this.systemRecorder && this.systemRecorder.state === 'recording') {
          console.log('üõë Stopping system recorder to process chunks');
          this.systemRecorder.stop();
        }
        
        // Schedule next processing
        setTimeout(processChunks, this.config.chunkDuration);
      }
    };

    setTimeout(processChunks, this.config.chunkDuration);
  }

  /**
   * üé§ Process microphone audio (Host speech)
   */
  private async processMicrophoneAudio(): Promise<void> {
    if (this.micChunks.length === 0) return;

    const audioBlob = new Blob(this.micChunks, { type: 'audio/webm' });
    this.micChunks = [];
    
    // üîá Skip silent audio to prevent Whisper hallucinations
    if (audioBlob.size < 1000) {
      console.log('üîá Skipping silent microphone audio chunk');
      return;
    }
    
    // Restart recorder if still recording
    if (this.isRecording && this.micStream) {
      this.micRecorder = new MediaRecorder(this.micStream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      this.micRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.micChunks.push(event.data);
        }
      };
      this.micRecorder.onstop = () => this.processMicrophoneAudio();
      this.micRecorder.start();
    }

    // Transcribe with Host speaker tag
    await this.transcribeAudio(audioBlob, 'Host', 'microphone');
  }

  /**
   * üîä Process system audio (Guest speech)
   */
  private async processSystemAudio(): Promise<void> {
    if (this.systemChunks.length === 0) return;

    const audioBlob = new Blob(this.systemChunks, { type: 'audio/webm' });
    this.systemChunks = [];
    
    // üîá Skip silent audio to prevent Whisper hallucinations
    if (audioBlob.size < 1000) {
      console.log('üîá Skipping silent system audio chunk');
      return;
    }
    
    // Restart recorder if still recording
    if (this.isRecording && this.systemStream) {
      this.systemRecorder = new MediaRecorder(this.systemStream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      this.systemRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.systemChunks.push(event.data);
        }
      };
      this.systemRecorder.onstop = () => this.processSystemAudio();
      this.systemRecorder.start();
    }

    // Transcribe with Guest speaker tag
    await this.transcribeAudio(audioBlob, 'Guest', 'system');
  }

  /**
   * üéØ Transcribe audio and perform source comparison
   */
  private async transcribeAudio(
    audioBlob: Blob, 
    speaker: 'Host' | 'Guest',
    audioSource: 'microphone' | 'system'
  ): Promise<void> {
    try {
      console.log(`üì§ Transcribing ${speaker} audio (${audioBlob.size} bytes) from ${audioSource}`);
      
      const now = Date.now();
      if (now - this.lastTranscriptionTime < this.config.minInterval) {
        console.log('‚è≥ Rate limited - skipping transcription');
        return; // Rate limiting
      }

      const formData = new FormData();
      formData.append('audio', audioBlob, 'audio.webm');
      formData.append('model', this.config.transcriptionModel);
      formData.append('speaker', speaker); // üéØ GUARANTEED SPEAKER ID
      formData.append('audioSource', audioSource); // Track the physics

      console.log(`üì° Sending to: ${this.config.transcriptionApiUrl}`);
      
      const response = await fetch(this.config.transcriptionApiUrl, {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        throw new Error(`Transcription API error: ${response.status}`);
      }

      const result = await response.json();
      console.log(`üì• Transcription response:`, result);
      
      // Handle both response formats (segments array or direct text)
      const transcriptText = result.text || (result.segments && result.segments[0]?.text) || '';
      
      if (transcriptText && transcriptText.trim()) {
        // üéØ SOURCE COMPARISON: Add to pending transcripts
        const pending: PendingTranscript = {
          speaker: speaker,
          text: transcriptText.trim(),
          timestamp: new Date(),
          audioSource: audioSource
        };

        const resolvedTranscripts = this.sourceComparison.addTranscript(pending);
        
        // Process resolved transcripts
        for (const resolved of resolvedTranscripts) {
          const message: TranscriptMessage = {
                id: `${resolved.speaker}_${Date.now()}_${Math.random()}`,
                timestamp: resolved.timestamp,
                speaker: resolved.speaker, // üéØ SOURCE COMPARISON TRUTH
                text: resolved.text,
                audioSource: resolved.audioSource
              };

              if (this.onTranscriptCallback) {
                console.log('üîî Calling transcript callback with:', message);
                this.onTranscriptCallback(message);
              } else {
                console.warn('‚ö†Ô∏è No transcript callback registered!');
              }

          if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
            console.log(`üìù ${resolved.speaker} (${resolved.audioSource}): "${resolved.text.substring(0, 50)}${resolved.text.length > 50 ? '...' : ''}"`);
          }
        }
      }

      this.lastTranscriptionTime = now;
    } catch (error) {
      console.error(`‚ùå Transcription failed for ${speaker}:`, error);
      this.handleError(`Transcription failed: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * ‚èπÔ∏è Stop recording
   */
  stopRecording(): void {
    if (!this.isRecording) return;

    this.isRecording = false;

    if (this.micRecorder && this.micRecorder.state !== 'inactive') {
      this.micRecorder.stop();
    }

    if (this.systemRecorder && this.systemRecorder.state !== 'inactive') {
      this.systemRecorder.stop();
    }

    if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
      console.log('‚èπÔ∏è Dual audio recording stopped');
    }
  }

  /**
   * üßπ Cleanup resources
   */
  cleanup(): void {
    this.stopRecording();

    if (this.micStream) {
      this.micStream.getTracks().forEach(track => track.stop());
      this.micStream = null;
    }

    if (this.systemStream) {
      this.systemStream.getTracks().forEach(track => track.stop());
      this.systemStream = null;
    }

    this.micRecorder = null;
    this.systemRecorder = null;
    this.micChunks = [];
    this.systemChunks = [];

    if (surgicalFlags.ENABLE_AUDIO_DEBUG_LOGS) {
      console.log('üßπ Dual audio capture cleaned up');
    }
  }

  /**
   * üìû Callback setters
   */
  onTranscript(callback: (message: TranscriptMessage) => void): void {
    this.onTranscriptCallback = callback;
  }

  onError(callback: (error: string) => void): void {
    this.onErrorCallback = callback;
  }

  /**
   * üîá Mute/unmute microphone
   */
  setMuted(muted: boolean): void {
    this.isMuted = muted;
    if (this.micStream) {
      this.micStream.getAudioTracks().forEach(track => {
        track.enabled = !muted;
      });
    }
    console.log(`üé§ Microphone ${muted ? 'muted' : 'unmuted'}`);
  }

  isMicMuted(): boolean {
    return this.isMuted;
  }

  /**
   * ‚ùå Error handling
   */
  private handleError(message: string): void {
    console.error('üö® DualAudioCapture Error:', message);
    if (this.onErrorCallback) {
      this.onErrorCallback(message);
    }
  }

  /**
   * üìä Status checks
   */
  isInitialized(): boolean {
    return this.micStream !== null;
  }

  hasSystemAudio(): boolean {
    return this.systemStream !== null;
  }

  isCurrentlyRecording(): boolean {
    return this.isRecording;
  }

  getStatus() {
    return {
      initialized: this.isInitialized(),
      hasSystemAudio: this.hasSystemAudio(),
      recording: this.isCurrentlyRecording(),
      mode: this.hasSystemAudio() ? 'DUAL_STREAM' : 'SINGLE_STREAM_FALLBACK'
    };
  }
}

/**
 * ü©∫ SURGICAL NOTES:
 * 
 * This class replaces the Grand Deception with physics-based truth:
 * - Microphone = Host speaking (you)
 * - System audio = Guest speaking (them)
 * - No AI voice recognition needed
 * - 100% accurate speaker identification
 * 
 * The old system relied on OpenAI's Speaker_0/Speaker_1 which was essentially
 * a coin flip. This system uses the actual audio routing to determine who's talking.
 * 
 * It's not AI. It's not smart. It's just physics. And physics doesn't lie.
 */